#!/usr/bin/env python3
"""
train_pipeline_strategyA_v4.py

Strateji A (v4, gÃ¼ncellenmiÅŸ):  
  1) Veri Train/Validation/Test olarak bÃ¶lÃ¼nÃ¼r (%60/%20/%20).  
  2) Age, Days_Indoors, Mood_Swings, Growing_Stress sÃ¼tunlarÄ± iÃ§in 
     daha ince binleme yÃ¶ntemleri (4 kategoriye Ã§Ä±karmak veya farklÄ± aralÄ±klar) uygulanÄ±r.  
  3) Quarantine_Frustrations, Growing_Stress, Mood_Swings, Weight_Change, Mental_Health_History  
     sÃ¼tunlarÄ± Ã¼zerinden yeni oran ve etkileÅŸim Ã¶zellikleri eklenir:
       - Frustration_Stress_Ratio
       - Frustration_Stress_SqRatio
       - Stress_Sq_Frustration
       - Frustration_Stress_Diff
       - Mood_Days_Product
       - Weight_Med_History_Ratio
       - Weight_x_History
  4) DecisionTreeClassifier Ã¼zerinde daha dar ancak etkili bir hiperparametre Ä±zgarasÄ± 
     ve farklÄ± class_weight seÃ§enekleriyle (balanced + manuel ayarlar) GridSearchCV yapÄ±lÄ±r.  
  5) Best model Validation ve Test metrikleri (accuracy, ROC-AUC, PR-AUC) ile raporlanÄ±r.
"""

from pathlib import Path
import pandas as pd
import joblib
import numpy as np
import matplotlib.pyplot as plt

from sklearn.pipeline        import Pipeline
from sklearn.preprocessing   import FunctionTransformer, OneHotEncoder
from sklearn.compose         import ColumnTransformer
from sklearn.model_selection import (
    train_test_split,
    KFold,
    GridSearchCV,
    cross_val_score
)
from sklearn.metrics         import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    average_precision_score,
    RocCurveDisplay,
    PrecisionRecallDisplay
)
from sklearn.tree            import DecisionTreeClassifier

from preprocessing           import preprocess_data

ROOT_DIR = Path(__file__).parents[1]
RAW_PATH = ROOT_DIR / 'data' / 'raw' / 'mental_health_finaldata_1.csv'
MODEL_DIR = ROOT_DIR / 'models'
MODEL_DIR.mkdir(parents=True, exist_ok=True)

def finer_ordinal_bins(df: pd.DataFrame) -> pd.DataFrame:
    """
    Daha ince aralÄ±klÄ± binleme:
      - Age (0â†’18-20, 1â†’21-25, 2â†’26-30, 3â†’31+)
      - Days_Indoors: 0, 1, 2-3, 4+
      - Mood_Swings: 0-1, 2, 3, 4+
      - Growing_Stress: 0-1, 2, 3, 4+
    Age iÃ§in Age_Group sÃ¼tunu, diÄŸerleri iÃ§in boolean bayraklar eklenir.
    """
    df2 = df.copy()

    # --- Age binning (4 kategori zaten var: 0,1,2,3) ---
    age_map = {0: '18_20', 1: '21_25', 2: '26_30', 3: '31_plus'}
    df2['Age_Group'] = df2['Age'].map(age_map)

    # --- Days_Indoors binning: 0, 1, 2-3, 4+ ---
    df2['Indoor_0']      = (df2['Days_Indoors'] == 0).astype(int)
    df2['Indoor_1']      = (df2['Days_Indoors'] == 1).astype(int)
    df2['Indoor_2_3']    = ((df2['Days_Indoors'] >= 2) & (df2['Days_Indoors'] <= 3)).astype(int)
    df2['Indoor_4_plus'] = (df2['Days_Indoors'] >= 4).astype(int)

    # --- Mood_Swings binning: 0-1, 2, 3, 4+ ---
    df2['Mood_0_1']   = (df2['Mood_Swings'] <= 1).astype(int)
    df2['Mood_2']     = (df2['Mood_Swings'] == 2).astype(int)
    df2['Mood_3']     = (df2['Mood_Swings'] == 3).astype(int)
    df2['Mood_4_plus']= (df2['Mood_Swings'] >= 4).astype(int)

    # --- Growing_Stress binning: 0-1, 2, 3, 4+ ---
    df2['Stress_0_1']   = (df2['Growing_Stress'] <= 1).astype(int)
    df2['Stress_2']     = (df2['Growing_Stress'] == 2).astype(int)
    df2['Stress_3']     = (df2['Growing_Stress'] == 3).astype(int)
    df2['Stress_4_plus']= (df2['Growing_Stress'] >= 4).astype(int)

    return df2

def add_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Yeni oran ve etkileÅŸim Ã¶zellikleri:
      - Frustration_Stress_Ratio        = Quarantine_Frustrations / (Growing_Stress + 1)
      - Frustration_Stress_SqRatio      = (Quarantine_Frustrations^2) / (Growing_Stress + 1)
      - Stress_Sq_Frustration           = (Growing_Stress^2) / (Quarantine_Frustrations + 1)
      - Frustration_Stress_Diff         = Quarantine_Frustrations - Growing_Stress
      - Mood_Days_Product               = Mood_Swings * Days_Indoors
      - Weight_Med_History_Ratio        = Weight_Change / (Mental_Health_History + 1)
      - Weight_x_History                 = Weight_Change * Mental_Health_History
    """
    df2 = df.copy()
    df2['Frustration_Stress_Ratio']    = df2['Quarantine_Frustrations'] / (df2['Growing_Stress'] + 1)
    df2['Frustration_Stress_SqRatio']  = (df2['Quarantine_Frustrations'] ** 2) / (df2['Growing_Stress'] + 1)
    df2['Stress_Sq_Frustration']       = (df2['Growing_Stress'] ** 2) / (df2['Quarantine_Frustrations'] + 1)
    df2['Frustration_Stress_Diff']     = df2['Quarantine_Frustrations'] - df2['Growing_Stress']
    df2['Mood_Days_Product']           = df2['Mood_Swings'] * df2['Days_Indoors']
    df2['Weight_Med_History_Ratio']    = df2['Weight_Change'] / (df2['Mental_Health_History'] + 1)
    df2['Weight_x_History']            = df2['Weight_Change'] * df2['Mental_Health_History']
    return df2

def build_preprocessing_pipeline():
    """
    Age_Group iÃ§in one-hot encoder, diÄŸer sÃ¼tunlar passthrough (boolean bayraklar + diÄŸer numeric).
    """
    onehot_age = Pipeline([
        ('select_age', FunctionTransformer(lambda df: df[['Age_Group']], validate=False)),
        ('oh',        OneHotEncoder(sparse_output=False))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('age_ohe', onehot_age, ['Age_Group']),
        ],
        remainder='passthrough'
    )
    return preprocessor

def full_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    """
    1) preprocess_dataâ€™dan gelen DataFrameâ€™i alÄ±r.
    2) finer_ordinal_bins ile ordinal sÃ¼tunlarÄ± 4â€™lÃ¼ veya daha ince kategorilere ayÄ±rÄ±r.
    3) add_advanced_features ile ek oran/etkileÅŸim sÃ¼tunlarÄ± ekler.
    4) build_preprocessing_pipeline ile Age_Groupâ€™u one-hot, diÄŸer tÃ¼m sÃ¼tunlarÄ± passthrough ederek 
       nihai bir Ã¶zellik DataFrameâ€™i dÃ¶ner.
    """
    # 1) Ordinal sÃ¼tunlarÄ± daha ince binleme
    df_binned = finer_ordinal_bins(df)

    # 2) Yeni oran/etkileÅŸim Ã¶zellikleri
    df_adv = add_advanced_features(df_binned)

    # 3) ColumnTransformer (Age_Group one-hot) uygula
    preprocessor = build_preprocessing_pipeline()
    transformed = preprocessor.fit_transform(df_adv)

    # Age_Group one-hot sÃ¼tun adlarÄ±nÄ± al
    age_ohe_categories = preprocessor.named_transformers_['age_ohe']\
                             .named_steps['oh']\
                             .get_feature_names_out(input_features=['Age_Group'])

    # Passthrough edilen sÃ¼tunlar
    passthrough_cols = [col for col in df_adv.columns if col != 'Age_Group']

    # SonuÃ§ DataFrame: Ã¶nce Age one-hot, sonra kalan sÃ¼tunlar
    df_final = pd.DataFrame(
        np.hstack([transformed[:, :len(age_ohe_categories)], transformed[:, len(age_ohe_categories):]]),
        columns=list(age_ohe_categories) + passthrough_cols,
        index=df_adv.index
    )
    return df_final

def plot_roc_pr(y_true, y_prob, title_suffix=""):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    RocCurveDisplay.from_predictions(y_true, y_prob, ax=ax1)
    ax1.set_title(f"ROC Curve {title_suffix}")
    PrecisionRecallDisplay.from_predictions(y_true, y_prob, ax=ax2)
    ax2.set_title(f"Precision-Recall Curve {title_suffix}")
    plt.tight_layout()
    plt.show()

def evaluate_classification(y_true, y_pred):
    print("=== Classification Report ===")
    print(classification_report(y_true, y_pred))
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,4))
    im = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(im, ax=ax)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')
    ax.set_xticks([0,1])
    ax.set_yticks([0,1])
    ax.set_title("Confusion Matrix")
    plt.show()

def main():
    # --- 1) Veri yÃ¼kle ve preprocess_data (ordinal mapping + base one-hot + target encode) ---
    df_raw  = pd.read_csv(RAW_PATH)
    df_proc = preprocess_data(df_raw)  # categoricalâ†’one-hot, ordinalâ†’code
    X_all   = df_proc.drop('Coping_Struggles', axis=1)
    y_all   = df_proc['Coping_Struggles']

    # --- 2) Train/Validation/Test split (%60/%20/%20) ---
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        X_all, y_all,
        test_size=0.20,
        stratify=y_all,
        random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_trainval, y_trainval,
        test_size=0.25,  # 0.25 * 0.80 = 0.20 overall
        stratify=y_trainval,
        random_state=42
    )

    print(f"Dataset daÄŸÄ±lÄ±mÄ±:")
    print(f"  - Train    (total %): {len(X_train)}/{len(X_all)} = {len(X_train)/len(X_all):.2f}")
    print(f"  - Val      (total %): {len(X_val)}/{len(X_all)} = {len(X_val)/len(X_all):.2f}")
    print(f"  - Test     (total %): {len(X_test)}/{len(X_all)} = {len(X_test)/len(X_all):.2f}\n")

    # --- 3) Pipeline tanÄ±mÄ±: FE + DT sÄ±nÄ±flayÄ±cÄ± ---
    pipeline = Pipeline([
        ('fe',  FunctionTransformer(full_feature_engineering, validate=False)),
        ('clf', DecisionTreeClassifier(random_state=42))
    ])

    # --- 4) Hiperparametre Ä±zgarasÄ± (v4) ---
    param_grid = {
        'clf__max_depth':        [3, 5, 8],
        'clf__min_samples_leaf': [1, 2, 5],
        'clf__min_samples_split':[2, 5, 10],
        'clf__criterion':        ['gini', 'entropy'],
        'clf__ccp_alpha':        [5e-4, 1e-3, 2e-3],
        'clf__class_weight':     [
            'balanced',
            {0: 0.4, 1: 0.6},
            {0: 0.3, 1: 0.7},
            {0: 0.2, 1: 0.8}
        ]
    }

    cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)
    grid_search = GridSearchCV(
        estimator=pipeline,
        param_grid=param_grid,
        cv=cv_inner,
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1
    )

    # --- 5) GridSearchCV (sadece X_train, y_train Ã¼zerinde) ---
    print("ğŸ”§ GridSearchCV baÅŸlÄ±yor (Training set Ã¼zerinde)...")
    grid_search.fit(X_train, y_train)

    print("\nğŸ“Œ En iyi parametreler:")
    print(grid_search.best_params_)
    best_pipeline = grid_search.best_estimator_

    # --- 6) Trainâ€CV skorlarÄ± (en iyi modelle) ---
    scores_acc  = cross_val_score(best_pipeline, X_train, y_train, cv=cv_inner, scoring='accuracy', n_jobs=-1)
    scores_auc  = cross_val_score(best_pipeline, X_train, y_train, cv=cv_inner, scoring='roc_auc',    n_jobs=-1)
    print(f"\nğŸ” Trainâ€CV Acc skorlarÄ±:  {scores_acc}")
    print(f"ğŸ” Ortalama Trainâ€CV Acc  : {scores_acc.mean():.4f}")
    print(f"ğŸ” Trainâ€CV ROC-AUC skorlarÄ±: {scores_auc}")
    print(f"ğŸ” Ortalama Trainâ€CV ROC-AUC: {scores_auc.mean():.4f}\n")

    # --- 7) Validation set Ã¼zerinde deÄŸerlendirme ---
    print("=== Validation Set PerformansÄ± ===")
    best_pipeline.fit(X_train, y_train)
    y_val_pred = best_pipeline.predict(X_val)
    y_val_prob = best_pipeline.predict_proba(X_val)[:, 1]

    evaluate_classification(y_val, y_val_pred)
    roc_val = roc_auc_score(y_val, y_val_prob)
    pr_val  = average_precision_score(y_val, y_val_prob)
    print(f"Val ROC-AUC: {roc_val:.3f}")
    print(f"Val PR-AUC : {pr_val:.3f}")
    plot_roc_pr(y_val, y_val_prob, title_suffix="(Validation Set)")

    # --- 8) Final model: X_train+X_val birleÅŸik set Ã¼zerinde fit ve test ---
    print("\nğŸ”„ Final eÄŸitim: X_train+X_val birleÅŸik setâ€™i kullanÄ±yoruz.")
    X_trainval_all = pd.concat([X_train, X_val], axis=0)
    y_trainval_all = pd.concat([y_train, y_val], axis=0)

    final_pipeline = Pipeline([
        ('fe',  FunctionTransformer(full_feature_engineering, validate=False)),
        ('clf', DecisionTreeClassifier(
            max_depth        = grid_search.best_params_['clf__max_depth'],
            min_samples_leaf = grid_search.best_params_['clf__min_samples_leaf'],
            min_samples_split= grid_search.best_params_['clf__min_samples_split'],
            criterion        = grid_search.best_params_['clf__criterion'],
            ccp_alpha        = grid_search.best_params_['clf__ccp_alpha'],
            class_weight     = grid_search.best_params_['clf__class_weight'],
            random_state=42
        ))
    ])
    final_pipeline.fit(X_trainval_all, y_trainval_all)

    print("\n=== TEST SET PerformansÄ± ===")
    y_test_pred = final_pipeline.predict(X_test)
    y_test_prob = final_pipeline.predict_proba(X_test)[:, 1]

    evaluate_classification(y_test, y_test_pred)
    roc_test = roc_auc_score(y_test, y_test_prob)
    pr_test  = average_precision_score(y_test, y_test_prob)
    print(f"Test ROC-AUC: {roc_test:.3f}")
    print(f"Test PR-AUC : {pr_test:.3f}")
    plot_roc_pr(y_test, y_test_prob, title_suffix="(Test Set)")

    # --- 9) Feature Importances (Top 10) ---
    clf = final_pipeline.named_steps['clf']
    fe_step = final_pipeline.named_steps['fe']
    X_test_fe = fe_step.transform(X_test.copy())
    feature_names = list(X_test_fe.columns)
    importances = clf.feature_importances_
    idxs = np.argsort(importances)[-10:]

    plt.figure(figsize=(6, 4))
    plt.barh([feature_names[i] for i in idxs], importances[idxs])
    plt.title("Top 10 Feature Importances")
    plt.xlabel("Importance")
    plt.tight_layout()
    plt.show()

    # --- 10) Modeli kaydet ---
    save_path = MODEL_DIR / 'decision_tree_stratA_v4.pkl'
    joblib.dump(final_pipeline, save_path)
    print(f"\nğŸ’¾ Final pipeline (StratejiA_v4) kaydedildi: {save_path}")

if __name__ == '__main__':
    main()
