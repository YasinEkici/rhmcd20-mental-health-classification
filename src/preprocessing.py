# preprocessing.py

import pandas as pd
from pathlib import Path
from sklearn.impute import SimpleImputer

# ---------- Dosya Yol TanÄ±mlarÄ± (eÄŸer doÄŸrudan kullanmak isterseniz) ----------
# RAW_PATH: Proje kÃ¶k dizininden bir Ã¼st klasÃ¶re Ã§Ä±kÄ±p, data/raw/mental_health_finaldata_1.csv dosyasÄ±nÄ± iÅŸaret eder.
# BÃ¶ylece fonksiyonlarÄ± dÄ±ÅŸarÄ±dan doÄŸrudan Ã§aÄŸÄ±rÄ±rken bu sabit yol Ã¼zerinden ham veriyi okuyabiliriz.
RAW_PATH = Path(__file__).parents[1] / 'data' / 'raw' / 'mental_health_finaldata_1.csv'


def load_data(path: Path) -> pd.DataFrame:
    """
    Verilen path'ten CSV dosyasÄ±nÄ± pandas DataFrame olarak yÃ¼kleyip dÃ¶ndÃ¼rÃ¼r.

    Parametreler:
    -----------
    path : Path
        YÃ¼klenecek CSV dosyasÄ±nÄ±n dosya sistemi yolu (Ã¶rneÄŸin: RAW_PATH).

    DÃ¶nÃ¼ÅŸ:
    ------
    pd.DataFrame
        CSV iÃ§eriÄŸini barÄ±ndÄ±ran pandas DataFrame. BaÅŸlÄ±k satÄ±rlarÄ± ve veri tipleri
        otomatik olarak algÄ±lanÄ±r. Eksik (NaN) deÄŸerler pandas tarafÄ±ndan NaN olarak temsil edilir.
    """
    # pd.read_csv ile CSV dosyasÄ±nÄ± okutuyoruz. EÄŸer dosya bulunamazsa hata fÄ±rlatÄ±r.
    return pd.read_csv(path)


def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ham DataFrame Ã¼zerinde ayrÄ±ntÄ±lÄ± Ã¶niÅŸleme adÄ±mlarÄ± gerÃ§ekleÅŸtirir ve tamamen sayÄ±sal bir DataFrame dÃ¶ner.

    Ã–niÅŸleme AdÄ±mlarÄ±:
    1) Eksik deÄŸer raporu: Her bir sÃ¼tundaki eksik (NaN) deÄŸer sayÄ±sÄ±nÄ± hesaplayÄ±p ekrana yazdÄ±rÄ±r.
    2) Manuel ordinal eÅŸlemeler: Metinsel kategorik verileri (Age, Days_Indoors, Mood_Swings vb.)
       Ã¶nceden tanÄ±mlÄ± sÄ±ralÄ± (ordinal) sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. EÄŸer hatalÄ± veya beklenmeyen
       bir kategori gelmiÅŸse map sonrasÄ± NaN dÃ¶necektir; bunlar sonraki adÄ±mda doldurulacaktÄ±r.
    3) Eksik sayÄ±sal deÄŸerler iÃ§in SimpleImputer (medyan stratejisi) uygulanÄ±r.
       Yani sÃ¼tun iÃ§inde kalan NaN deÄŸerler o sÃ¼tunun medyanÄ±yla doldurulur.
    4) Nominal/kategorik sÃ¼tunlar (Gender, Occupation, Work_Interest, Social_Weakness) iÃ§in
       one-hot encode (dummy deÄŸiÅŸkenler) uygulanÄ±r. BÃ¶ylece her kategori iÃ§in yeni bir sÃ¼tun oluÅŸturulur.
       drop_first=True ile bir kategori referans alÄ±nÄ±r ve ona karÅŸÄ±lÄ±k gelen sÃ¼tun dÃ¼ÅŸÃ¼rÃ¼lÃ¼r,
       bÃ¶ylece multikolineeritenin Ã¶nÃ¼ne geÃ§ilmiÅŸ olur.
    5) Target sÃ¼tunu (Coping_Struggles) eÄŸer string veya kategori tÃ¼rÃ¼nde ise kategori kodlarÄ±na
       dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r (Ã¶rneÄŸin "No" â†’ 0, "Maybe" â†’ 1, "Yes" â†’ 2). EÄŸer zaten sayÄ±salsa dokunulmaz.
    6) SonuÃ§ olarak tamamen sayÄ±sal (integer veya float) sÃ¼tunlardan oluÅŸan bir DataFrame dÃ¶ndÃ¼rÃ¼lÃ¼r.
       Bu, daha sonra makine Ã¶ÄŸrenmesi modellerinde (sklearn vb.) kullanÄ±lmak Ã¼zere hazÄ±r halidir.

    Parametreler:
    -----------
    df : pd.DataFrame
        Ham pandas DataFrame. YÃ¼klenen CSV'den direkt gelen ve henÃ¼z Ã¶niÅŸlenmemiÅŸ verileri iÃ§erir.

    DÃ¶nÃ¼ÅŸ:
    ------
    pd.DataFrame
        Tamamen sayÄ±sal sÃ¼tunlardan oluÅŸan, eksik deÄŸerleri doldurulmuÅŸ ve kategorik
        sÃ¼tunlarÄ± sayÄ±sal kodlamaya Ã§evrilmiÅŸ DataFrame. Ä°Ã§erisinde hedef deÄŸiÅŸken (Coping_Struggles)
        de sayÄ±sal bir kodlamaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ ÅŸekliyle yer alÄ±r.
    """
    # ------------------------------------------------------------------------------------------------
    # 1) Eksik deÄŸerler raporu
    # ------------------------------------------------------------------------------------------------
    # DataFrame.isnull().sum() ile her bir sÃ¼tundaki NaN sayÄ±sÄ±nÄ± alÄ±yoruz.
    missing = df.isnull().sum()
    # Eksik deÄŸer raporunu ekrana Ã§ok detaylÄ± bir ÅŸekilde yazdÄ±rÄ±yoruz.
    print("ğŸ” SÃ¼tun bazÄ±nda eksik deÄŸer sayÄ±larÄ±:\n", missing, "\n")

    # ------------------------------------------------------------------------------------------------
    # 2) Manuel ordinal mapping (sÄ±ralÄ± kategorik verilerin sayÄ±sallaÅŸtÄ±rÄ±lmasÄ±)
    # ------------------------------------------------------------------------------------------------
    # age_map: Age sÃ¼tununda beklenen kategorik deÄŸerler ve bunlarÄ±n sÄ±ralÄ± sayÄ±sal karÅŸÄ±lÄ±klarÄ±.
    age_map = {
        "16-20": 0,
        "20-25": 1,
        "25-30": 2,
        "30-Above": 3
    }
    # days_map: Days_Indoors sÃ¼tununda beklenen kategorik deÄŸerler ve sÄ±ralÄ± sayÄ±sal karÅŸÄ±lÄ±klarÄ±.
    days_map = {
        "Go out Every day":   0,
        "1-14 days":          1,
        "15-30 days":         2,
        "31-60 days":         3,
        "More than 2 months": 4
    }
    # mood_map: Mood_Swings sÃ¼tununda beklenen kategorik deÄŸerler ve sÄ±ralÄ± sayÄ±sal karÅŸÄ±lÄ±klarÄ±.
    mood_map = {
        "Low":    0,
        "Medium": 1,
        "High":   2
    }
    # yesno_map: Bir dizi sÃ¼tun ("Yes"/"No"/"Maybe") yanÄ±tlarÄ±nÄ± sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in.
    yesno_map = {
        "No":    0,
        "Maybe": 1,
        "Yes":   2
    }

    # Age sÃ¼tununu age_map sÃ¶zlÃ¼ÄŸÃ¼ne gÃ¶re eÅŸliyoruz. EÄŸerbeklenmeyen bir string gelirse NaN olur.
    df["Age"] = df["Age"].map(age_map)
    # Days_Indoors sÃ¼tununu days_map sÃ¶zlÃ¼ÄŸÃ¼ne gÃ¶re eÅŸliyoruz.
    df["Days_Indoors"] = df["Days_Indoors"].map(days_map)
    # Mood_Swings sÃ¼tununu mood_map sÃ¶zlÃ¼ÄŸÃ¼ne gÃ¶re eÅŸliyoruz.
    df["Mood_Swings"] = df["Mood_Swings"].map(mood_map)

    # Birden fazla sÃ¼tun iÃ§in aynÄ± eÅŸleme (yesno_map) uygulanÄ±yor.
    # Bu sÃ¼tunlar string "Yes"/"No"/"Maybe" ÅŸeklinde geldiÄŸi varsayÄ±lÄ±yor.
    for col in [
        "Growing_Stress",
        "Quarantine_Frustrations",
        "Changes_Habits",
        "Mental_Health_History",
        "Weight_Change"
    ]:
        # Her sÃ¼tunu eÅŸleme ile sayÄ±sal deÄŸerlere Ã§eviriyoruz.
        df[col] = df[col].map(yesno_map)

    # ------------------------------------------------------------------------------------------------
    # 3) Eksik sayÄ±sal deÄŸerler iÃ§in SimpleImputer (medyan stratejisi)
    # ------------------------------------------------------------------------------------------------
    # num_cols listesi: sayÄ±sal olmasÄ± gereken ve yukarÄ±daki map iÅŸlemi sonrasÄ± NaN kalmÄ±ÅŸ sÃ¼tunlarÄ± iÃ§erir.
    num_cols = [
        "Age",
        "Days_Indoors",
        "Growing_Stress",
        "Quarantine_Frustrations",
        "Changes_Habits",
        "Mental_Health_History",
        "Weight_Change",
        "Mood_Swings"
    ]
    # SimpleImputer: eksik deÄŸerleri belirttiÄŸimiz stratejiye gÃ¶re doldurur.
    # strategy='median' demek, her sÃ¼tunun kendi medyan deÄŸerini hesaplar ve NaN'larÄ± bu medyanla doldurur.
    imputer = SimpleImputer(strategy='median')
    # fit_transform: Ã¶nce ilgili sÃ¼tunlarÄ±n medyanÄ±nÄ± hesaplar, ardÄ±ndan her NaN'Ä± o medyanla doldurur.
    df[num_cols] = imputer.fit_transform(df[num_cols])

    # ------------------------------------------------------------------------------------------------
    # 4) Nominal (kategorik) sÃ¼tunlara one-hot encode (dummy deÄŸiÅŸkenler)
    # ------------------------------------------------------------------------------------------------
    # get_dummies ile kategorik sÃ¼tunlarÄ± dummies sÃ¼tunlarÄ±na Ã§eviriyoruz.
    # drop_first=True, bir kategori referans alÄ±nacaÄŸÄ± iÃ§in bir sÃ¼tun dÃ¼ÅŸÃ¼rÃ¼lÃ¼r.
    # Bu, Ã§oklu doÄŸrusal baÄŸlantÄ± (multicollinearity) sorununu azaltmaya yardÄ±mcÄ± olur.
    nom_cols = ["Gender", "Occupation", "Work_Interest", "Social_Weakness"]
    # orijinal DataFrame Ã¼zerine one-hot encoding uygulanarak yeni sÃ¼tunlar eklenir.
    df = pd.get_dummies(df, columns=nom_cols, drop_first=True)

    # ------------------------------------------------------------------------------------------------
    # 5) Target sÃ¼tunu (Coping_Struggles) numeric hale Ã§evirme
    # ------------------------------------------------------------------------------------------------
    # EÄŸer hedef sÃ¼tunu hÃ¢len object veya category tÃ¼rÃ¼ndeyse:
    if df["Coping_Struggles"].dtype.name in ['object', 'category']:
        # pandas'Ä±n category kodlama yÃ¶ntemini kullanÄ±yoruz.
        # Ã–rneÄŸin: EÄŸer "Coping_Struggles" sÃ¼tununda "No" ve "Yes" gibi deÄŸerler varsa,
        # bunlar otomatik olarak 0 ve 1 ÅŸeklinde kodlanÄ±r. (Alfabetik sÄ±ra bazlÄ± veya label sÄ±rasÄ±na gÃ¶re)
        df["Coping_Struggles"] = df["Coping_Struggles"].astype('category').cat.codes
    else:
        # EÄŸer sÃ¼tun zaten sayÄ±sal tipindeyse (int64 veya float64 gibi), bu adÄ±mda hiÃ§birÅŸey yapÄ±lmaz.
        pass

    # ------------------------------------------------------------------------------------------------
    # 6) SonuÃ§: tamamen sayÄ±sal bir DataFrame dÃ¶ndÃ¼rme
    # ------------------------------------------------------------------------------------------------
    # ArtÄ±k df iÃ§indeki tÃ¼m sÃ¼tunlar sayÄ±sal tipte (int veya float) ve eksik deÄŸerlerden arÄ±ndÄ±rÄ±lmÄ±ÅŸ durumda.
    return df


# ----------------------------------------------
# EÄŸer bu dosyayÄ± doÄŸrudan bir komut satÄ±rÄ± aracÄ±
# olarak Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z (python preprocessing.py),
# aÅŸaÄŸÄ±daki bÃ¶lÃ¼m devreye girer ve preprocess_data'nÄ±n
# doÄŸru Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± hÄ±zlÄ±ca test edebilirsiniz.
# ----------------------------------------------
if __name__ == "__main__":
    # 1) Ham veriyi oku: RAW_PATH sabitinde tanÄ±mlÄ± olan dosya yolundan CSV'yi yÃ¼kle.
    df_raw = load_data(RAW_PATH)

    # 2) Ã–niÅŸleme fonksiyonunu Ã§alÄ±ÅŸtÄ±r ve Ã§Ä±ktÄ±sÄ±nÄ± df_clean deÄŸiÅŸkenine ata.
    df_clean = preprocess_data(df_raw)

    # 3) Ã–niÅŸlenmiÅŸ veriden bir Ã¶rnek satÄ±rÄ± ekrana yazdÄ±r.
    print("\nğŸ“‹ Ã–niÅŸlenmiÅŸ DataFrame'den ilk Ã¶rnek satÄ±rlar:\n", df_clean.head(), "\n")
    # 4) BaÅŸarÄ± mesajÄ± bas: preprocess_data fonksiyonunun sorunsuz Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterir.
    print("â„¹ï¸ preprocess_data fonksiyonu baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±.")
