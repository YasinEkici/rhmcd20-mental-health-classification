#!/usr/bin/env python3
"""
train_pipeline_strategyA_v2.py

Strateji A (GÃ¼ncellenmiÅŸ): Veriyi Train/Validation/Test olarak bÃ¶ler,
SMOTEâ€™u kaldÄ±rÄ±r, class_weight dengesi ve yeniden ayarlanmÄ±ÅŸ hiperparametre Ä±zgarasÄ±
kullanarak Decision Tree modelini eÄŸitir ve final performansÄ± test seti Ã¼zerinde raporlar.
"""

from pathlib import Path
import pandas as pd
import joblib
import numpy as np
import matplotlib.pyplot as plt

from sklearn.pipeline        import Pipeline
from sklearn.preprocessing   import FunctionTransformer
from sklearn.model_selection import (
    train_test_split,
    KFold,
    GridSearchCV,
    cross_val_score
)
from sklearn.metrics         import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    average_precision_score,
    RocCurveDisplay,
    PrecisionRecallDisplay
)
from sklearn.tree            import DecisionTreeClassifier

from preprocessing           import preprocess_data
from feature_engineering     import engineer_features

ROOT_DIR = Path(__file__).parents[1]
RAW_PATH = ROOT_DIR / 'data' / 'raw' / 'mental_health_finaldata_1.csv'
MODEL_DIR = ROOT_DIR / 'models'
MODEL_DIR.mkdir(parents=True, exist_ok=True)

def plot_roc_pr(y_true, y_prob, title_suffix=""):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    RocCurveDisplay.from_predictions(y_true, y_prob, ax=ax1)
    ax1.set_title(f"ROC Curve {title_suffix}")
    PrecisionRecallDisplay.from_predictions(y_true, y_prob, ax=ax2)
    ax2.set_title(f"Precision-Recall Curve {title_suffix}")
    plt.tight_layout()
    plt.show()

def evaluate_classification(y_true, y_pred):
    print("=== Classification Report ===")
    print(classification_report(y_true, y_pred))
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,4))
    im = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(im, ax=ax)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')
    ax.set_xticks([0,1])
    ax.set_yticks([0,1])
    ax.set_title("Confusion Matrix")
    plt.show()

def main():
    # --- 1) Veri yÃ¼kle ve Ã¶n iÅŸleme ---
    df_raw = pd.read_csv(RAW_PATH)
    df_proc = preprocess_data(df_raw)  # ordinal mapping + one-hot + target encode
    X = df_proc.drop('Coping_Struggles', axis=1)
    y = df_proc['Coping_Struggles']

    # --- 2) Train/Validation/Test split (%60/%20/%20) ---
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        X, y,
        test_size=0.20,
        stratify=y,
        random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_trainval, y_trainval,
        test_size=0.25,  # 0.25 * 0.80 = 0.20 overall
        stratify=y_trainval,
        random_state=42
    )

    print(f"Dataset daÄŸÄ±lÄ±mÄ±:")
    print(f"  - Train    (total %): {len(X_train)}/{len(X)} = {len(X_train)/len(X):.2f}")
    print(f"  - Val      (total %): {len(X_val)}/{len(X)} = {len(X_val)/len(X):.2f}")
    print(f"  - Test     (total %): {len(X_test)}/{len(X)} = {len(X_test)/len(X):.2f}\n")

    # --- 3) Pipeline tanÄ±mÄ± (SMOTE kaldÄ±rÄ±ldÄ±) ---
    pipeline = Pipeline([
        ('fe',  FunctionTransformer(engineer_features, validate=False)),
        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
    ])

    # --- 4) Yeniden ayarlanmÄ±ÅŸ hiperparametre Ä±zgarasÄ± ---
    param_grid = {
        'clf__max_depth':        [None, 3, 5, 8],
        'clf__min_samples_leaf': [1, 2, 5, 10],
        'clf__min_samples_split':[2, 5, 10, 20],
        'clf__criterion':        ['gini', 'entropy'],
        'clf__ccp_alpha':        [0.0, 1e-5, 1e-4, 5e-4, 1e-3]
    }

    cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)
    grid_search = GridSearchCV(
        estimator=pipeline,
        param_grid=param_grid,
        cv=cv_inner,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )

    # --- 5) GridSearchCV (sadece X_train, y_train Ã¼zerinde) ---
    print("ğŸ”§ GridSearchCV baÅŸlÄ±yor (Training set Ã¼zerinde)...")
    grid_search.fit(X_train, y_train)

    print("\nğŸ“Œ En iyi parametreler:")
    print(grid_search.best_params_)
    best_pipeline = grid_search.best_estimator_

    # --- 6) Train-CV skorlarÄ± (en iyi modelle) ---
    scores_traincv = cross_val_score(
        best_pipeline, X_train, y_train,
        cv=cv_inner, scoring='accuracy', n_jobs=-1
    )
    print(f"\nğŸ” En iyi model ile Train-CV skorlarÄ±: {scores_traincv}")
    print(f"ğŸ” Ortalama Train-CV doÄŸruluk: {scores_traincv.mean():.4f}\n")

    # --- 7) Validation set Ã¼zerinde deÄŸerlendirme ---
    print("=== Validation Set PerformansÄ± ===")
    best_pipeline.fit(X_train, y_train)
    y_val_pred = best_pipeline.predict(X_val)
    y_val_prob = best_pipeline.predict_proba(X_val)[:, 1]

    evaluate_classification(y_val, y_val_pred)
    roc_val = roc_auc_score(y_val, y_val_prob)
    pr_val  = average_precision_score(y_val, y_val_prob)
    print(f"Val ROC-AUC: {roc_val:.3f}")
    print(f"Val PR-AUC : {pr_val:.3f}")
    plot_roc_pr(y_val, y_val_prob, title_suffix="(Validation Set)")

    # --- 8) Final model: X_train+X_val birleÅŸik set Ã¼zerinde fit ve test ---
    print("\nğŸ”„ Final eÄŸitim: X_train+X_val birleÅŸik setâ€™i kullanÄ±yoruz.")
    X_trainval_all = pd.concat([X_train, X_val], axis=0)
    y_trainval_all = pd.concat([y_train, y_val], axis=0)

    final_pipeline = Pipeline([
        ('fe',  FunctionTransformer(engineer_features, validate=False)),
        ('clf', DecisionTreeClassifier(
            max_depth        = grid_search.best_params_['clf__max_depth'],
            min_samples_leaf = grid_search.best_params_['clf__min_samples_leaf'],
            min_samples_split= grid_search.best_params_['clf__min_samples_split'],
            criterion        = grid_search.best_params_['clf__criterion'],
            ccp_alpha        = grid_search.best_params_['clf__ccp_alpha'],
            random_state=42,
            class_weight='balanced'
        ))
    ])
    final_pipeline.fit(X_trainval_all, y_trainval_all)

    print("\n=== TEST SET PerformansÄ± ===")
    y_test_pred = final_pipeline.predict(X_test)
    y_test_prob = final_pipeline.predict_proba(X_test)[:, 1]

    evaluate_classification(y_test, y_test_pred)
    roc_test = roc_auc_score(y_test, y_test_prob)
    pr_test  = average_precision_score(y_test, y_test_prob)
    print(f"Test ROC-AUC: {roc_test:.3f}")
    print(f"Test PR-AUC : {pr_test:.3f}")
    plot_roc_pr(y_test, y_test_prob, title_suffix="(Test Set)")

    # --- 9) Feature Importances ---
    clf = final_pipeline.named_steps['clf']
    fe_step = final_pipeline.named_steps['fe']
    X_test_fe = fe_step.transform(X_test.copy())
    feature_names = list(X_test_fe.columns)
    importances = clf.feature_importances_
    idxs = np.argsort(importances)[-10:]

    plt.figure(figsize=(6, 4))
    plt.barh([feature_names[i] for i in idxs], importances[idxs])
    plt.title("Top 10 Feature Importances")
    plt.xlabel("Importance")
    plt.tight_layout()
    plt.show()

    # --- 10) Modeli kaydet ---
    save_path = MODEL_DIR / 'decision_tree_stratA_v2.pkl'
    joblib.dump(final_pipeline, save_path)
    print(f"\nğŸ’¾ Final pipeline (StratejiA_v2) kaydedildi: {save_path}")

if __name__ == '__main__':
    main()
