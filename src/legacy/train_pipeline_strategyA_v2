#!/usr/bin/env python3
"""
train_pipeline_strategyA_v2.py

Strateji A (Güncellenmiş): Veriyi Train/Validation/Test olarak böler,
SMOTE’u kaldırır, class_weight dengesi ve yeniden ayarlanmış hiperparametre ızgarası
kullanarak Decision Tree modelini eğitir ve final performansı test seti üzerinde raporlar.
"""

from pathlib import Path
import pandas as pd
import joblib
import numpy as np
import matplotlib.pyplot as plt

from sklearn.pipeline        import Pipeline
from sklearn.preprocessing   import FunctionTransformer
from sklearn.model_selection import (
    train_test_split,
    KFold,
    GridSearchCV,
    cross_val_score
)
from sklearn.metrics         import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    average_precision_score,
    RocCurveDisplay,
    PrecisionRecallDisplay
)
from sklearn.tree            import DecisionTreeClassifier

from preprocessing           import preprocess_data
from feature_engineering     import engineer_features

ROOT_DIR = Path(__file__).parents[1]
RAW_PATH = ROOT_DIR / 'data' / 'raw' / 'mental_health_finaldata_1.csv'
MODEL_DIR = ROOT_DIR / 'models'
MODEL_DIR.mkdir(parents=True, exist_ok=True)

def plot_roc_pr(y_true, y_prob, title_suffix=""):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    RocCurveDisplay.from_predictions(y_true, y_prob, ax=ax1)
    ax1.set_title(f"ROC Curve {title_suffix}")
    PrecisionRecallDisplay.from_predictions(y_true, y_prob, ax=ax2)
    ax2.set_title(f"Precision-Recall Curve {title_suffix}")
    plt.tight_layout()
    plt.show()

def evaluate_classification(y_true, y_pred):
    print("=== Classification Report ===")
    print(classification_report(y_true, y_pred))
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,4))
    im = ax.matshow(cm, cmap=plt.cm.Blues)
    fig.colorbar(im, ax=ax)
    ax.set_xlabel('Predicted')
    ax.set_ylabel('Actual')
    ax.set_xticks([0,1])
    ax.set_yticks([0,1])
    ax.set_title("Confusion Matrix")
    plt.show()

def main():
    # --- 1) Veri yükle ve ön işleme ---
    df_raw = pd.read_csv(RAW_PATH)
    df_proc = preprocess_data(df_raw)  # ordinal mapping + one-hot + target encode
    X = df_proc.drop('Coping_Struggles', axis=1)
    y = df_proc['Coping_Struggles']

    # --- 2) Train/Validation/Test split (%60/%20/%20) ---
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        X, y,
        test_size=0.20,
        stratify=y,
        random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_trainval, y_trainval,
        test_size=0.25,  # 0.25 * 0.80 = 0.20 overall
        stratify=y_trainval,
        random_state=42
    )

    print(f"Dataset dağılımı:")
    print(f"  - Train    (total %): {len(X_train)}/{len(X)} = {len(X_train)/len(X):.2f}")
    print(f"  - Val      (total %): {len(X_val)}/{len(X)} = {len(X_val)/len(X):.2f}")
    print(f"  - Test     (total %): {len(X_test)}/{len(X)} = {len(X_test)/len(X):.2f}\n")

    # --- 3) Pipeline tanımı (SMOTE kaldırıldı) ---
    pipeline = Pipeline([
        ('fe',  FunctionTransformer(engineer_features, validate=False)),
        ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
    ])

    # --- 4) Yeniden ayarlanmış hiperparametre ızgarası ---
    param_grid = {
        'clf__max_depth':        [None, 3, 5, 8],
        'clf__min_samples_leaf': [1, 2, 5, 10],
        'clf__min_samples_split':[2, 5, 10, 20],
        'clf__criterion':        ['gini', 'entropy'],
        'clf__ccp_alpha':        [0.0, 1e-5, 1e-4, 5e-4, 1e-3]
    }

    cv_inner = KFold(n_splits=5, shuffle=True, random_state=42)
    grid_search = GridSearchCV(
        estimator=pipeline,
        param_grid=param_grid,
        cv=cv_inner,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )

    # --- 5) GridSearchCV (sadece X_train, y_train üzerinde) ---
    print("🔧 GridSearchCV başlıyor (Training set üzerinde)...")
    grid_search.fit(X_train, y_train)

    print("\n📌 En iyi parametreler:")
    print(grid_search.best_params_)
    best_pipeline = grid_search.best_estimator_

    # --- 6) Train-CV skorları (en iyi modelle) ---
    scores_traincv = cross_val_score(
        best_pipeline, X_train, y_train,
        cv=cv_inner, scoring='accuracy', n_jobs=-1
    )
    print(f"\n🔍 En iyi model ile Train-CV skorları: {scores_traincv}")
    print(f"🔍 Ortalama Train-CV doğruluk: {scores_traincv.mean():.4f}\n")

    # --- 7) Validation set üzerinde değerlendirme ---
    print("=== Validation Set Performansı ===")
    best_pipeline.fit(X_train, y_train)
    y_val_pred = best_pipeline.predict(X_val)
    y_val_prob = best_pipeline.predict_proba(X_val)[:, 1]

    evaluate_classification(y_val, y_val_pred)
    roc_val = roc_auc_score(y_val, y_val_prob)
    pr_val  = average_precision_score(y_val, y_val_prob)
    print(f"Val ROC-AUC: {roc_val:.3f}")
    print(f"Val PR-AUC : {pr_val:.3f}")
    plot_roc_pr(y_val, y_val_prob, title_suffix="(Validation Set)")

    # --- 8) Final model: X_train+X_val birleşik set üzerinde fit ve test ---
    print("\n🔄 Final eğitim: X_train+X_val birleşik set’i kullanıyoruz.")
    X_trainval_all = pd.concat([X_train, X_val], axis=0)
    y_trainval_all = pd.concat([y_train, y_val], axis=0)

    final_pipeline = Pipeline([
        ('fe',  FunctionTransformer(engineer_features, validate=False)),
        ('clf', DecisionTreeClassifier(
            max_depth        = grid_search.best_params_['clf__max_depth'],
            min_samples_leaf = grid_search.best_params_['clf__min_samples_leaf'],
            min_samples_split= grid_search.best_params_['clf__min_samples_split'],
            criterion        = grid_search.best_params_['clf__criterion'],
            ccp_alpha        = grid_search.best_params_['clf__ccp_alpha'],
            random_state=42,
            class_weight='balanced'
        ))
    ])
    final_pipeline.fit(X_trainval_all, y_trainval_all)

    print("\n=== TEST SET Performansı ===")
    y_test_pred = final_pipeline.predict(X_test)
    y_test_prob = final_pipeline.predict_proba(X_test)[:, 1]

    evaluate_classification(y_test, y_test_pred)
    roc_test = roc_auc_score(y_test, y_test_prob)
    pr_test  = average_precision_score(y_test, y_test_prob)
    print(f"Test ROC-AUC: {roc_test:.3f}")
    print(f"Test PR-AUC : {pr_test:.3f}")
    plot_roc_pr(y_test, y_test_prob, title_suffix="(Test Set)")

    # --- 9) Feature Importances ---
    clf = final_pipeline.named_steps['clf']
    fe_step = final_pipeline.named_steps['fe']
    X_test_fe = fe_step.transform(X_test.copy())
    feature_names = list(X_test_fe.columns)
    importances = clf.feature_importances_
    idxs = np.argsort(importances)[-10:]

    plt.figure(figsize=(6, 4))
    plt.barh([feature_names[i] for i in idxs], importances[idxs])
    plt.title("Top 10 Feature Importances")
    plt.xlabel("Importance")
    plt.tight_layout()
    plt.show()

    # --- 10) Modeli kaydet ---
    save_path = MODEL_DIR / 'decision_tree_stratA_v2.pkl'
    joblib.dump(final_pipeline, save_path)
    print(f"\n💾 Final pipeline (StratejiA_v2) kaydedildi: {save_path}")

if __name__ == '__main__':
    main()
